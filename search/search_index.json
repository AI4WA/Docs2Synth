{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Docs2Synth","text":"Document Processing &amp; Retriever Training Toolkit    <p>     A complete pipeline for converting, synthesizing, and training retrievers for your document datasets   </p>"},{"location":"#key-features","title":"Key Features","text":""},{"location":"#document-processing","title":"Document Processing","text":"<p>Convert raw documents using MinerU or other OCR methods. Supports PDFs, images, and complex layouts.</p> <p>Learn more \u2192</p>"},{"location":"#agent-based-qa-generation","title":"Agent-Based QA Generation","text":"<p>Automatically generate high-quality question-answer pairs with two-step verification (meaningfulness + correctness).</p> <p>Learn more \u2192</p>"},{"location":"#retriever-training","title":"Retriever Training","text":"<p>Train custom retrievers using LayoutLMv3, BERT, or sentence transformers on your domain-specific data.</p> <p>Learn more \u2192</p>"},{"location":"#rag-path","title":"RAG Path","text":"<p>Deploy immediately with out-of-box strategies (BM25, dense, hybrid) - no training required.</p> <p>Learn more \u2192</p>"},{"location":"#benchmarking","title":"Benchmarking","text":"<p>Track retrieval performance with Hit@K, MRR, NDCG metrics and monitor end-to-end latency.</p> <p>Learn more \u2192</p>"},{"location":"#extensible-pipeline","title":"Extensible Pipeline","text":"<p>Combine all steps into a unified pipeline with flexible control flow based on your requirements.</p> <p>Get Started \u2192</p>"},{"location":"#installation","title":"Installation","text":""},{"location":"#from-github","title":"From GitHub","text":"<pre><code>pip install git+https://github.com/AI4WA/Docs2Synth.git\n</code></pre>"},{"location":"#from-pypi-once-released","title":"From PyPI (once released)","text":"<pre><code>pip install docs2synth\n</code></pre>"},{"location":"#quick-start","title":"Quick Start","text":""},{"location":"#development-setup","title":"Development Setup","text":"<pre><code># Clone repository\ngit clone https://github.com/AI4WA/Docs2Synth.git\ncd Docs2Synth\n\n# Create virtual environment (Python \u22653.8)\npython -m venv .venv &amp;&amp; source .venv/bin/activate\n\n# Install editable package with dev dependencies\npip install -e \".[dev]\"\n</code></pre>"},{"location":"#using-conda","title":"Using Conda","text":"<pre><code># Create and activate environment (Python 3.10)\nconda env create -f environment.yml\nconda activate Docs2Synth\n\n# Verify installation\npytest\n</code></pre>"},{"location":"#basic-usage","title":"Basic Usage","text":""},{"location":"#generate-qa-pairs","title":"Generate QA Pairs","text":"<pre><code>docs2synth generate-qa /path/to/documents /path/to/output.jsonl\n</code></pre>"},{"location":"#train-a-retriever","title":"Train a Retriever","text":"<pre><code>docs2synth train-retriever /path/to/qa_pairs.jsonl \\\n    --output-dir models/retriever \\\n    --model-name sentence-transformers/all-MiniLM-L6-v2\n</code></pre>"},{"location":"#workflow","title":"Workflow","text":"<p>The typical Docs2Synth workflow follows these stages:</p> <ol> <li>Document Processing: OCR and preprocessing</li> <li>QA Generation: Generate and verify question-answer pairs</li> <li>Retriever Training: Train custom retrieval models</li> <li>RAG Path: Deploy without training using pre-built strategies</li> </ol>"},{"location":"#architecture","title":"Architecture","text":"<pre><code>Docs2Synth/\n\u251c\u2500\u2500 integration/    # Integration utilities\n\u251c\u2500\u2500 preprocess/     # Document preprocessing\n\u251c\u2500\u2500 qa/            # QA generation and verification\n\u251c\u2500\u2500 retriever/     # Retriever training and inference\n\u251c\u2500\u2500 rag/           # RAG strategies\n\u2514\u2500\u2500 utils/         # Logging, timing, and utilities\n</code></pre>"},{"location":"#contributing","title":"Contributing","text":"<p>We welcome contributions! Please see our GitHub repository for guidelines.</p>"},{"location":"#license","title":"License","text":"<p>This project is licensed under the MIT License.</p>"},{"location":"#support","title":"Support","text":"<ul> <li>Report issues: GitHub Issues</li> <li>Documentation: Full documentation</li> </ul>"},{"location":"api-reference/","title":"API Reference","text":"<p>Complete API documentation for Docs2Synth modules.</p> <p>Documentation Status</p> <p>This API reference will be automatically generated from docstrings as modules are implemented. Currently showing manual documentation for implemented modules.</p>"},{"location":"api-reference/#preprocess","title":"Preprocess","text":"<p>Document preprocessing and OCR functionality.</p>"},{"location":"api-reference/#docs2synthpreprocessocr","title":"<code>Docs2Synth.preprocess.ocr</code>","text":"<p>Functions for OCR processing using various engines (MinerU, Tesseract, Cloud APIs).</p> <p>Coming soon - See Document Processing for usage examples.</p>"},{"location":"api-reference/#docs2synthpreprocessmineru","title":"<code>Docs2Synth.preprocess.mineru</code>","text":"<p>MinerU-specific OCR implementation for high-quality document extraction.</p> <p>Coming soon - See Document Processing for usage examples.</p>"},{"location":"api-reference/#qa-generation","title":"QA Generation","text":"<p>Question-answer pair generation and verification.</p>"},{"location":"api-reference/#docs2synthqagenerator","title":"<code>Docs2Synth.qa.generator</code>","text":"<p>Core QA generation functionality using LLMs.</p> <p>Coming soon - See QA Generation for usage examples.</p>"},{"location":"api-reference/#docs2synthqaverification","title":"<code>Docs2Synth.qa.verification</code>","text":"<p>Two-step verification system (meaningfulness + correctness checking).</p> <p>Coming soon - See QA Generation for usage examples.</p>"},{"location":"api-reference/#retriever","title":"Retriever","text":"<p>Retriever training, inference, and evaluation.</p>"},{"location":"api-reference/#docs2synthretrievertrain","title":"<code>Docs2Synth.retriever.train</code>","text":"<p>Training functionality for custom retrievers.</p> <p>Coming soon - See Retriever Training for usage examples.</p>"},{"location":"api-reference/#docs2synthretrievermodels","title":"<code>Docs2Synth.retriever.models</code>","text":"<p>Model architectures (LayoutLMv3, BERT variants, sentence transformers).</p> <p>Coming soon - See Retriever Training for usage examples.</p>"},{"location":"api-reference/#docs2synthretrieverinference","title":"<code>Docs2Synth.retriever.inference</code>","text":"<p>Inference and retrieval functionality for trained models.</p> <p>Coming soon - See Retriever Training for usage examples.</p>"},{"location":"api-reference/#docs2synthretrieverevaluation","title":"<code>Docs2Synth.retriever.evaluation</code>","text":"<p>Evaluation metrics and benchmarking tools.</p> <p>Coming soon - See Retriever Training for usage examples.</p>"},{"location":"api-reference/#rag","title":"RAG","text":"<p>RAG retrieval strategies and pipelines.</p>"},{"location":"api-reference/#docs2synthrag","title":"<code>Docs2Synth.rag</code>","text":"<p>Out-of-box retrieval strategies (BM25, dense, hybrid, ColBERT).</p> <p>Coming soon - See RAG Path for usage examples.</p>"},{"location":"api-reference/#utils","title":"Utils","text":"<p>Utilities for logging, timing, and more.</p>"},{"location":"api-reference/#docs2synthutilslogging","title":"<code>Docs2Synth.utils.logging</code>","text":"<p>::: Docs2Synth.utils.logging     options:       show_root_heading: true       show_source: true       members:         - setup_logging         - get_logger         - setup_cli_logging         - LoggerContext         - ProgressLogger</p>"},{"location":"api-reference/#docs2synthutilstimer","title":"<code>Docs2Synth.utils.timer</code>","text":"<p>::: Docs2Synth.utils.timer     options:       show_root_heading: true       show_source: true       members:         - timer         - timeit         - Timer         - format_time</p>"},{"location":"api-reference/#cli","title":"CLI","text":"<p>Command-line interface documentation.</p>"},{"location":"api-reference/#docs2synth","title":"<code>docs2synth</code>","text":"<p>Main CLI entry point.</p> <pre><code>docs2synth --help\n</code></pre> <p>Available Commands:</p>"},{"location":"api-reference/#generate-qa","title":"<code>generate-qa</code>","text":"<p>Generate question-answer pairs from documents.</p> <pre><code>docs2synth generate-qa INPUT OUTPUT [OPTIONS]\n</code></pre> <p>Arguments: - <code>INPUT</code>: Path to source documents - <code>OUTPUT</code>: Path to save generated QA pairs</p> <p>Options: - <code>--num-pairs INTEGER</code>: Number of QA pairs to generate per document - <code>--model TEXT</code>: LLM model to use (default: gpt-4) - <code>--verify</code>: Enable verification pipeline - <code>--help</code>: Show help message</p>"},{"location":"api-reference/#train-retriever","title":"<code>train-retriever</code>","text":"<p>Train a retriever model on QA pairs.</p> <pre><code>docs2synth train-retriever QA_PATH [OPTIONS]\n</code></pre> <p>Arguments: - <code>QA_PATH</code>: Path to QA pairs dataset</p> <p>Options: - <code>--output-dir TEXT</code>: Where to save trained model (default: models/retriever) - <code>--model-name TEXT</code>: Backbone model (default: sentence-transformers/all-MiniLM-L6-v2) - <code>--epochs INTEGER</code>: Number of training epochs (default: 5) - <code>--batch-size INTEGER</code>: Training batch size (default: 32) - <code>--learning-rate FLOAT</code>: Learning rate (default: 2e-5) - <code>--help</code>: Show help message</p>"},{"location":"api-reference/#type-definitions","title":"Type Definitions","text":""},{"location":"api-reference/#document","title":"Document","text":"<pre><code>class Document:\n    \"\"\"Represents a processed document.\"\"\"\n\n    text: str\n    layout: Dict[str, Any]\n    metadata: Dict[str, Any]\n    document_id: str\n</code></pre>"},{"location":"api-reference/#qapair","title":"QAPair","text":"<pre><code>class QAPair:\n    \"\"\"Represents a question-answer pair.\"\"\"\n\n    question: str\n    answer: str\n    context: str\n    metadata: Dict[str, Any]\n    meaningful_score: float\n    correctness_score: float\n</code></pre>"},{"location":"api-reference/#retrievalresult","title":"RetrievalResult","text":"<pre><code>class RetrievalResult:\n    \"\"\"Represents a retrieval result.\"\"\"\n\n    document_id: str\n    score: float\n    document: Document\n    rank: int\n</code></pre>"},{"location":"api-reference/#configuration","title":"Configuration","text":""},{"location":"api-reference/#configuration-file-format","title":"Configuration File Format","text":"<p>Docs2Synth supports YAML configuration files:</p> <pre><code># config.yml\npreprocess:\n  ocr_engine: mineru\n  language: eng\n  dpi: 300\n\nqa_generation:\n  model: gpt-4\n  temperature: 0.7\n  num_pairs_per_page: 5\n  verification:\n    enable_meaningful_check: true\n    enable_correctness_check: true\n\nretriever_training:\n  model_name: sentence-transformers/all-mpnet-base-v2\n  epochs: 5\n  batch_size: 32\n  learning_rate: 2e-5\n\nrag:\n  strategy: hybrid\n  sparse_weight: 0.3\n  dense_weight: 0.7\n</code></pre>"},{"location":"api-reference/#loading-configuration","title":"Loading Configuration","text":"<pre><code>from Docs2Synth import load_config\n\nconfig = load_config(\"config.yml\")\n</code></pre>"},{"location":"api-reference/#exceptions","title":"Exceptions","text":""},{"location":"api-reference/#docs2synthexceptions","title":"<code>Docs2Synth.exceptions</code>","text":"<pre><code>class Docs2SynthError(Exception):\n    \"\"\"Base exception for Docs2Synth.\"\"\"\n    pass\n\nclass OCRError(Docs2SynthError):\n    \"\"\"Raised when OCR processing fails.\"\"\"\n    pass\n\nclass QAGenerationError(Docs2SynthError):\n    \"\"\"Raised when QA generation fails.\"\"\"\n    pass\n\nclass TrainingError(Docs2SynthError):\n    \"\"\"Raised when retriever training fails.\"\"\"\n    pass\n\nclass RetrievalError(Docs2SynthError):\n    \"\"\"Raised when retrieval fails.\"\"\"\n    pass\n</code></pre>"},{"location":"api-reference/#examples","title":"Examples","text":"<p>For practical examples, see the workflow documentation and the examples directory in the repository.</p>"},{"location":"api-reference/#contributing","title":"Contributing","text":"<p>To contribute to the API documentation:</p> <ol> <li>Add docstrings to your code (Google-style format)</li> <li>Update this reference page if adding new modules</li> <li>Run <code>mkdocs serve</code> to preview changes</li> <li>Submit a pull request</li> </ol> <p>For more information, see the contributing guide.</p>"},{"location":"workflow/document-processing/","title":"Document Processing","text":"<p>The first step in the Docs2Synth workflow is processing raw documents into structured, machine-readable formats.</p>"},{"location":"workflow/document-processing/#overview","title":"Overview","text":"<p>Document processing converts various document formats (PDFs, images, scanned documents) into text and layout-aware representations that can be used for downstream tasks like QA generation and retrieval.</p>"},{"location":"workflow/document-processing/#supported-methods","title":"Supported Methods","text":""},{"location":"workflow/document-processing/#mineru","title":"MinerU","text":"<p>MinerU is the primary OCR method for extracting text and layout from documents.</p> <p>Features: - High-quality text extraction - Layout preservation - Support for complex documents (tables, multi-column layouts)</p> <p>Usage:</p> <pre><code>from Docs2Synth.preprocess import mineru\n\n# Process a single document\ndocument = mineru.process_document(\"path/to/document.pdf\")\n\n# Process a directory of documents\ndocuments = mineru.process_directory(\"path/to/documents/\")\n</code></pre>"},{"location":"workflow/document-processing/#other-ocr-methods","title":"Other OCR Methods","text":"<p>Docs2Synth supports integration with various OCR engines:</p> <ul> <li>Tesseract: Open-source OCR engine</li> <li>Google Cloud Vision API: Cloud-based OCR</li> <li>Amazon Textract: AWS OCR service</li> <li>Azure Form Recognizer: Microsoft OCR</li> </ul> <p>Generic OCR Interface:</p> <pre><code>from Docs2Synth.preprocess import ocr\n\n# Using Tesseract\ndocument = ocr.process_document(\n    \"path/to/document.pdf\",\n    engine=\"tesseract\"\n)\n\n# Using cloud services\ndocument = ocr.process_document(\n    \"path/to/document.pdf\",\n    engine=\"google_vision\",\n    api_key=\"your-api-key\"\n)\n</code></pre>"},{"location":"workflow/document-processing/#document-structure","title":"Document Structure","text":"<p>Processed documents are returned as structured objects containing:</p> <pre><code>{\n    \"text\": \"Full extracted text\",\n    \"layout\": {\n        \"pages\": [...],\n        \"blocks\": [...],\n        \"lines\": [...]\n    },\n    \"metadata\": {\n        \"page_count\": 10,\n        \"file_path\": \"path/to/document.pdf\",\n        \"processing_time\": 2.5\n    }\n}\n</code></pre>"},{"location":"workflow/document-processing/#best-practices","title":"Best Practices","text":""},{"location":"workflow/document-processing/#1-preprocessing","title":"1. Preprocessing","text":"<p>Clean and normalize documents before OCR:</p> <pre><code>from Docs2Synth.preprocess import preprocessing\n\n# Enhance image quality\nenhanced = preprocessing.enhance_image(\"document.jpg\")\n\n# Remove noise\ncleaned = preprocessing.denoise(enhanced)\n</code></pre>"},{"location":"workflow/document-processing/#2-batch-processing","title":"2. Batch Processing","text":"<p>For large document collections, use batch processing:</p> <pre><code>from Docs2Synth.preprocess import batch\n\n# Process documents in parallel\nresults = batch.process_documents(\n    input_dir=\"documents/\",\n    output_dir=\"processed/\",\n    num_workers=4,\n    ocr_engine=\"mineru\"\n)\n</code></pre>"},{"location":"workflow/document-processing/#3-quality-control","title":"3. Quality Control","text":"<p>Verify OCR quality before proceeding:</p> <pre><code>from Docs2Synth.preprocess import quality\n\n# Check OCR confidence\nquality_score = quality.assess_ocr_quality(document)\n\nif quality_score &lt; 0.8:\n    # Retry with different settings or manual review\n    document = ocr.process_document(\n        path,\n        engine=\"google_vision\"  # Try more robust engine\n    )\n</code></pre>"},{"location":"workflow/document-processing/#configuration","title":"Configuration","text":"<p>Configure processing parameters in <code>config.yml</code>:</p> <pre><code>preprocess:\n  ocr_engine: mineru\n  language: eng\n  dpi: 300\n  enhance_images: true\n  parallel_processing: true\n  num_workers: 4\n</code></pre>"},{"location":"workflow/document-processing/#error-handling","title":"Error Handling","text":"<p>Handle common processing errors:</p> <pre><code>from Docs2Synth.preprocess import ocr\nfrom Docs2Synth.preprocess.exceptions import OCRError\n\ntry:\n    document = ocr.process_document(\"document.pdf\")\nexcept OCRError as e:\n    print(f\"OCR failed: {e}\")\n    # Fallback to alternative method\n</code></pre>"},{"location":"workflow/document-processing/#next-steps","title":"Next Steps","text":"<p>After processing documents, proceed to QA Generation to create question-answer pairs from the extracted content.</p>"},{"location":"workflow/document-processing/#api-reference","title":"API Reference","text":"<p>For detailed API documentation, see the API Reference.</p>"},{"location":"workflow/qa-generation/","title":"QA Generation","text":"<p>Generate high-quality question-answer pairs from processed documents using agent-based approaches with built-in verification.</p>"},{"location":"workflow/qa-generation/#overview","title":"Overview","text":"<p>The QA generation workflow uses LLM-based agents to automatically create question-answer pairs from document content, with a two-step verification process to ensure quality.</p>"},{"location":"workflow/qa-generation/#architecture","title":"Architecture","text":"<pre><code>Document Content\n      \u2193\nQA Pair Generation (LLM)\n      \u2193\nMeaningful Verifier (Agent 1)\n      \u2193\nCorrectness Checker (Agent 2)\n      \u2193\nHuman Judgement (Optional)\n      \u2193\nFinal QA Dataset\n</code></pre>"},{"location":"workflow/qa-generation/#basic-usage","title":"Basic Usage","text":""},{"location":"workflow/qa-generation/#simple-generation","title":"Simple Generation","text":"<pre><code>from Docs2Synth.qa import generator\n\n# Generate QA pairs from a document\nqa_pairs = generator.generate_qa_pairs(\n    document_content=\"Your document text here\",\n    num_pairs=10\n)\n\n# Output format\n# [\n#   {\n#     \"question\": \"What is...\",\n#     \"answer\": \"The answer is...\",\n#     \"context\": \"Relevant excerpt from document\",\n#     \"metadata\": {...}\n#   }\n# ]\n</code></pre>"},{"location":"workflow/qa-generation/#cli-usage","title":"CLI Usage","text":"<pre><code># Generate QA pairs from processed documents\ndocs2synth generate-qa /path/to/documents /path/to/output.jsonl\n\n# With custom settings\ndocs2synth generate-qa \\\n    /path/to/documents \\\n    /path/to/output.jsonl \\\n    --num-pairs 50 \\\n    --model gpt-4 \\\n    --verify\n</code></pre>"},{"location":"workflow/qa-generation/#qa-generation-strategy","title":"QA Generation Strategy","text":""},{"location":"workflow/qa-generation/#single-page-context","title":"Single-Page Context","text":"<p>Generate QA pairs from individual pages:</p> <pre><code>from Docs2Synth.qa import generator\n\n# Single-page generation\nqa_pairs = generator.generate_from_page(\n    page_content=page_text,\n    page_number=1,\n    num_pairs=5\n)\n</code></pre>"},{"location":"workflow/qa-generation/#multi-page-context-future","title":"Multi-Page Context (Future)","text":"<p>For complex questions spanning multiple pages:</p> <pre><code># Coming soon: multi-page context\nqa_pairs = generator.generate_from_pages(\n    pages=[page1, page2, page3],\n    num_pairs=10,\n    context_window=3\n)\n</code></pre>"},{"location":"workflow/qa-generation/#two-step-verification","title":"Two-Step Verification","text":""},{"location":"workflow/qa-generation/#1-meaningful-verifier","title":"1. Meaningful Verifier","text":"<p>Checks if the question is meaningful and answerable:</p> <pre><code>from Docs2Synth.qa.verification import meaningful_verifier\n\n# Verify meaningfulness\nis_meaningful = meaningful_verifier.verify(\n    question=\"What is the capital of France?\",\n    context=\"France is a country in Europe...\"\n)\n# Returns: {\n#   \"is_meaningful\": True,\n#   \"reason\": \"Question is clear and answerable\",\n#   \"score\": 0.95\n# }\n</code></pre> <p>Criteria checked: - Question clarity and specificity - Answerability from context - Relevance to document content - Avoiding ambiguity</p>"},{"location":"workflow/qa-generation/#2-correctness-checker","title":"2. Correctness Checker","text":"<p>Verifies that the answer is accurate given the context:</p> <pre><code>from Docs2Synth.qa.verification import correctness_checker\n\n# Check correctness\nis_correct = correctness_checker.verify(\n    question=\"What is the capital of France?\",\n    answer=\"Paris\",\n    context=\"The capital of France is Paris...\"\n)\n# Returns: {\n#   \"is_correct\": True,\n#   \"confidence\": 0.98,\n#   \"issues\": []\n# }\n</code></pre> <p>Criteria checked: - Factual accuracy - Answer completeness - Consistency with context - No hallucinations</p>"},{"location":"workflow/qa-generation/#human-judgement","title":"Human Judgement","text":"<p>Quick human review for final quality control:</p> <pre><code>from Docs2Synth.qa import human_review\n\n# Review interface\nreviewed = human_review.annotate(\n    qa_pairs=qa_pairs,\n    output_file=\"reviewed_qa.jsonl\"\n)\n\n# Human annotator sees:\n# Question: \"What is...?\"\n# Answer: \"The answer is...\"\n# [Keep] [Discard] [Edit]\n</code></pre>"},{"location":"workflow/qa-generation/#cli-review-tool","title":"CLI Review Tool","text":"<pre><code># Launch interactive review interface\ndocs2synth review-qa qa_pairs.jsonl --output reviewed_qa.jsonl\n</code></pre>"},{"location":"workflow/qa-generation/#configuration","title":"Configuration","text":"<p>Configure QA generation in <code>config.yml</code>:</p> <pre><code>qa_generation:\n  model: gpt-4\n  temperature: 0.7\n  num_pairs_per_page: 5\n\n  verification:\n    enable_meaningful_check: true\n    enable_correctness_check: true\n    meaningful_threshold: 0.8\n    correctness_threshold: 0.85\n\n  human_review:\n    enable: true\n    sample_rate: 0.1  # Review 10% of pairs\n</code></pre>"},{"location":"workflow/qa-generation/#advanced-features","title":"Advanced Features","text":""},{"location":"workflow/qa-generation/#custom-prompts","title":"Custom Prompts","text":"<p>Customize the generation prompts:</p> <pre><code>from Docs2Synth.qa import generator\n\ncustom_prompt = \"\"\"\nGiven the following document excerpt, generate a question-answer pair\nfocusing on technical details and implementation specifics.\n\nDocument: {context}\n\nGenerate:\n\"\"\"\n\nqa_pairs = generator.generate_qa_pairs(\n    document_content=text,\n    prompt_template=custom_prompt\n)\n</code></pre>"},{"location":"workflow/qa-generation/#filtering-and-post-processing","title":"Filtering and Post-processing","text":"<pre><code>from Docs2Synth.qa import filters\n\n# Filter by quality scores\nhigh_quality = filters.filter_by_score(\n    qa_pairs,\n    min_meaningful_score=0.9,\n    min_correctness_score=0.9\n)\n\n# Remove duplicates\nunique_pairs = filters.remove_duplicates(qa_pairs)\n\n# Balance question types\nbalanced = filters.balance_question_types(qa_pairs)\n</code></pre>"},{"location":"workflow/qa-generation/#quality-metrics","title":"Quality Metrics","text":"<p>Track generation quality:</p> <pre><code>from Docs2Synth.qa import metrics\n\n# Evaluate generated QA pairs\nevaluation = metrics.evaluate_qa_dataset(qa_pairs)\n\nprint(evaluation)\n# {\n#   \"total_pairs\": 100,\n#   \"avg_meaningful_score\": 0.92,\n#   \"avg_correctness_score\": 0.89,\n#   \"question_type_distribution\": {...},\n#   \"avg_answer_length\": 45\n# }\n</code></pre>"},{"location":"workflow/qa-generation/#best-practices","title":"Best Practices","text":"<ol> <li>Start with high-quality documents: Better OCR \u2192 Better QA</li> <li>Use verification: Don't skip the two-step verification</li> <li>Human review sample: Review at least 10% manually</li> <li>Diverse question types: Ensure mix of factual, reasoning, and analytical questions</li> <li>Context preservation: Keep context snippets for debugging</li> </ol>"},{"location":"workflow/qa-generation/#data-format","title":"Data Format","text":"<p>Generated QA pairs are saved in JSONL format:</p> <pre><code>{\n  \"question\": \"What is the main purpose of the system?\",\n  \"answer\": \"The system is designed to process documents efficiently.\",\n  \"context\": \"The document processing system...\",\n  \"metadata\": {\n    \"document_id\": \"doc_001\",\n    \"page_number\": 5,\n    \"meaningful_score\": 0.95,\n    \"correctness_score\": 0.92,\n    \"generated_at\": \"2025-01-15T10:30:00Z\"\n  }\n}\n</code></pre>"},{"location":"workflow/qa-generation/#next-steps","title":"Next Steps","text":"<p>After generating QA pairs, proceed to Retriever Training to train custom retrieval models.</p>"},{"location":"workflow/qa-generation/#api-reference","title":"API Reference","text":"<p>For detailed API documentation, see the API Reference.</p>"},{"location":"workflow/rag-path/","title":"RAG Path","text":"<p>Deploy document retrieval systems using out-of-box strategies without training custom models.</p>"},{"location":"workflow/rag-path/#overview","title":"Overview","text":"<p>The RAG (Retrieval-Augmented Generation) path provides pre-built retrieval strategies that work immediately without requiring custom model training. Ideal for rapid prototyping, smaller datasets, or when training resources are limited.</p>"},{"location":"workflow/rag-path/#available-strategies","title":"Available Strategies","text":""},{"location":"workflow/rag-path/#bm25-sparse-retrieval","title":"BM25 (Sparse Retrieval)","text":"<p>Classic keyword-based retrieval using term frequency and inverse document frequency:</p> <pre><code>from Docs2Synth.rag import BM25Retriever\n\n# Initialize BM25 retriever\nretriever = BM25Retriever()\n\n# Index documents\nretriever.index_documents(document_corpus)\n\n# Retrieve\nresults = retriever.retrieve(\n    query=\"What is document processing?\",\n    top_k=5\n)\n</code></pre> <p>Pros: - No training required - Fast and efficient - Works well for keyword-based queries - Low memory footprint</p> <p>Cons: - Doesn't understand semantic meaning - Sensitive to exact keyword matches - Poor performance on paraphrased queries</p>"},{"location":"workflow/rag-path/#dense-retrieval-pre-trained","title":"Dense Retrieval (Pre-trained)","text":"<p>Use pre-trained sentence transformers:</p> <pre><code>from Docs2Synth.rag import DenseRetriever\n\n# Initialize with pre-trained model\nretriever = DenseRetriever(\n    model_name=\"sentence-transformers/all-mpnet-base-v2\"\n)\n\n# Index documents\nretriever.index_documents(document_corpus)\n\n# Retrieve\nresults = retriever.retrieve(\n    query=\"What is document processing?\",\n    top_k=5\n)\n</code></pre> <p>Available Models: - <code>all-mpnet-base-v2</code>: Best general-purpose model - <code>all-MiniLM-L6-v2</code>: Fast and lightweight - <code>multi-qa-mpnet-base-dot-v1</code>: Optimized for Q&amp;A - <code>msmarco-distilbert-base-v4</code>: Trained on MS MARCO dataset</p> <p>Pros: - Understands semantic similarity - Handles paraphrased queries - No training required</p> <p>Cons: - May not be optimal for specific domains - Slower than BM25 - Higher memory usage</p>"},{"location":"workflow/rag-path/#hybrid-retrieval","title":"Hybrid Retrieval","text":"<p>Combine sparse and dense retrieval:</p> <pre><code>from Docs2Synth.rag import HybridRetriever\n\n# Initialize hybrid retriever\nretriever = HybridRetriever(\n    sparse_weight=0.3,  # BM25 weight\n    dense_weight=0.7,   # Dense retriever weight\n    dense_model=\"sentence-transformers/all-mpnet-base-v2\"\n)\n\n# Index documents\nretriever.index_documents(document_corpus)\n\n# Retrieve\nresults = retriever.retrieve(\n    query=\"What is document processing?\",\n    top_k=5\n)\n</code></pre> <p>Pros: - Best of both worlds - Robust to different query types - Better overall performance</p> <p>Cons: - More complex setup - Slower than individual methods</p>"},{"location":"workflow/rag-path/#colbert-late-interaction","title":"ColBERT (Late Interaction)","text":"<p>Token-level matching for fine-grained retrieval:</p> <pre><code>from Docs2Synth.rag import ColBERTRetriever\n\n# Initialize ColBERT\nretriever = ColBERTRetriever(\n    model_name=\"colbert-ir/colbertv2.0\"\n)\n\n# Index documents (pre-compute token embeddings)\nretriever.index_documents(document_corpus)\n\n# Retrieve\nresults = retriever.retrieve(\n    query=\"What is document processing?\",\n    top_k=5\n)\n</code></pre> <p>Pros: - High accuracy - Captures fine-grained matches - Good for complex documents</p> <p>Cons: - High storage requirements - Slower indexing - More memory intensive</p>"},{"location":"workflow/rag-path/#quick-start-examples","title":"Quick Start Examples","text":""},{"location":"workflow/rag-path/#minimal-setup","title":"Minimal Setup","text":"<pre><code>from Docs2Synth.rag import QuickRetriever\n\n# Automatic strategy selection\nretriever = QuickRetriever.auto(\n    document_corpus=documents,\n    strategy=\"best\"  # or \"fast\", \"balanced\"\n)\n\n# Query\nresults = retriever.retrieve(\"your query here\", top_k=5)\n</code></pre>"},{"location":"workflow/rag-path/#with-configuration","title":"With Configuration","text":"<pre><code>from Docs2Synth.rag import QuickRetriever\n\nconfig = {\n    \"strategy\": \"hybrid\",\n    \"sparse_weight\": 0.3,\n    \"dense_weight\": 0.7,\n    \"index_type\": \"faiss\",\n    \"normalize_scores\": True\n}\n\nretriever = QuickRetriever(config)\nretriever.index_documents(documents)\n</code></pre>"},{"location":"workflow/rag-path/#indexing-strategies","title":"Indexing Strategies","text":""},{"location":"workflow/rag-path/#in-memory-index","title":"In-Memory Index","text":"<p>Fast, but limited by RAM:</p> <pre><code>retriever = DenseRetriever(index_type=\"memory\")\nretriever.index_documents(documents)\n</code></pre>"},{"location":"workflow/rag-path/#faiss-index","title":"FAISS Index","text":"<p>For large-scale retrieval:</p> <pre><code>from Docs2Synth.rag.indexing import FAISSIndex\n\nretriever = DenseRetriever(\n    index_type=\"faiss\",\n    index_config={\n        \"type\": \"IVF\",  # Inverted file index\n        \"nlist\": 100,   # Number of clusters\n        \"nprobe\": 10    # Number of clusters to search\n    }\n)\n\nretriever.index_documents(documents)\n</code></pre>"},{"location":"workflow/rag-path/#persistent-index","title":"Persistent Index","text":"<p>Save and load indexes:</p> <pre><code># Index and save\nretriever.index_documents(documents)\nretriever.save_index(\"my_index\")\n\n# Load later\nretriever = DenseRetriever.load_index(\"my_index\")\n</code></pre>"},{"location":"workflow/rag-path/#re-ranking","title":"Re-ranking","text":"<p>Improve retrieval quality with re-ranking:</p> <pre><code>from Docs2Synth.rag import ReRanker\n\n# Initial retrieval\nretriever = DenseRetriever()\ninitial_results = retriever.retrieve(query, top_k=100)\n\n# Re-rank top results\nreranker = ReRanker(\n    model_name=\"cross-encoder/ms-marco-MiniLM-L-6-v2\"\n)\n\nfinal_results = reranker.rerank(\n    query=query,\n    documents=initial_results,\n    top_k=5\n)\n</code></pre>"},{"location":"workflow/rag-path/#integration-with-llms","title":"Integration with LLMs","text":""},{"location":"workflow/rag-path/#rag-pipeline","title":"RAG Pipeline","text":"<pre><code>from Docs2Synth.rag import RAGPipeline\n\n# Complete RAG setup\nrag = RAGPipeline(\n    retriever_strategy=\"hybrid\",\n    llm=\"gpt-4\",\n    context_window=5\n)\n\n# Query and generate\nresponse = rag.query(\n    \"What are the main features of the system?\",\n    return_sources=True\n)\n\nprint(response.answer)\nprint(f\"Sources: {response.sources}\")\n</code></pre>"},{"location":"workflow/rag-path/#custom-prompts","title":"Custom Prompts","text":"<pre><code>from Docs2Synth.rag import RAGPipeline\n\nprompt_template = \"\"\"\nBased on the following context, answer the question.\n\nContext:\n{context}\n\nQuestion: {question}\n\nAnswer:\n\"\"\"\n\nrag = RAGPipeline(\n    retriever_strategy=\"dense\",\n    llm=\"gpt-4\",\n    prompt_template=prompt_template\n)\n\nresponse = rag.query(\"your question\")\n</code></pre>"},{"location":"workflow/rag-path/#evaluation","title":"Evaluation","text":""},{"location":"workflow/rag-path/#retrieval-metrics","title":"Retrieval Metrics","text":"<pre><code>from Docs2Synth.rag.evaluation import evaluate_retrieval\n\n# Evaluate retriever\nresults = evaluate_retrieval(\n    retriever=retriever,\n    test_queries=test_queries,\n    ground_truth=ground_truth,\n    metrics=[\"hit@1\", \"hit@5\", \"mrr\", \"ndcg@10\"]\n)\n\nprint(results)\n</code></pre>"},{"location":"workflow/rag-path/#end-to-end-evaluation","title":"End-to-End Evaluation","text":"<pre><code>from Docs2Synth.rag.evaluation import evaluate_rag\n\n# Evaluate complete RAG pipeline\nresults = evaluate_rag(\n    rag_pipeline=rag,\n    test_questions=questions,\n    ground_truth_answers=answers,\n    metrics=[\"accuracy\", \"faithfulness\", \"relevance\"]\n)\n</code></pre>"},{"location":"workflow/rag-path/#performance-optimization","title":"Performance Optimization","text":""},{"location":"workflow/rag-path/#batch-processing","title":"Batch Processing","text":"<pre><code># Process multiple queries efficiently\nqueries = [\"query 1\", \"query 2\", \"query 3\"]\n\nresults = retriever.batch_retrieve(\n    queries=queries,\n    top_k=5,\n    batch_size=32\n)\n</code></pre>"},{"location":"workflow/rag-path/#caching","title":"Caching","text":"<pre><code>from Docs2Synth.rag import CachedRetriever\n\n# Enable caching for repeated queries\nretriever = CachedRetriever(\n    base_retriever=DenseRetriever(),\n    cache_size=1000\n)\n</code></pre>"},{"location":"workflow/rag-path/#best-practices","title":"Best Practices","text":"<ol> <li>Start with hybrid retrieval: Best balance of performance and simplicity</li> <li>Use re-ranking for top results: Significantly improves precision</li> <li>Monitor latency: Track retrieval time in production</li> <li>Cache frequent queries: Reduce repeated computation</li> <li>Tune top_k: Usually 5-10 is sufficient for most applications</li> <li>Index optimization: Use FAISS for large document collections</li> </ol>"},{"location":"workflow/rag-path/#benchmarking","title":"Benchmarking","text":"<p>Compare different strategies:</p> <pre><code>from Docs2Synth.rag import benchmark_strategies\n\n# Compare multiple strategies\nresults = benchmark_strategies(\n    document_corpus=corpus,\n    test_queries=queries,\n    strategies=[\"bm25\", \"dense\", \"hybrid\", \"colbert\"],\n    metrics=[\"hit@5\", \"mrr\", \"latency\"]\n)\n\n# Generate comparison report\nbenchmark.generate_report(results, \"strategy_comparison.html\")\n</code></pre>"},{"location":"workflow/rag-path/#when-to-use-rag-vs-training","title":"When to Use RAG vs Training","text":"<p>Use RAG (No Training) when: - Quick prototyping needed - Small to medium datasets (&lt;100K documents) - Limited computational resources - General-purpose retrieval is sufficient</p> <p>Train Custom Retriever when: - Large-scale datasets (&gt;100K documents) - Highly specialized domain - Need optimal performance - Have computational resources</p>"},{"location":"workflow/rag-path/#next-steps","title":"Next Steps","text":"<ul> <li>Combine with trained retrievers for hybrid approaches</li> <li>Deploy to production with monitoring</li> <li>Iterate on prompt engineering for better LLM responses</li> </ul>"},{"location":"workflow/rag-path/#api-reference","title":"API Reference","text":"<p>For detailed API documentation, see the API Reference.</p>"},{"location":"workflow/retriever-training/","title":"Retriever Training","text":"<p>Train custom retrieval models on your QA dataset to build domain-specific document retrievers.</p>"},{"location":"workflow/retriever-training/#overview","title":"Overview","text":"<p>Docs2Synth supports training various retriever architectures, from lightweight sentence transformers to specialized document understanding models like LayoutLMv3.</p>"},{"location":"workflow/retriever-training/#supported-models","title":"Supported Models","text":""},{"location":"workflow/retriever-training/#sentence-transformers","title":"Sentence Transformers","text":"<p>Fast, efficient retrievers based on BERT and similar architectures:</p> <ul> <li><code>sentence-transformers/all-MiniLM-L6-v2</code> (Lightweight, fast)</li> <li><code>sentence-transformers/all-mpnet-base-v2</code> (Best quality/speed tradeoff)</li> <li><code>sentence-transformers/multi-qa-mpnet-base-dot-v1</code> (Optimized for QA)</li> </ul>"},{"location":"workflow/retriever-training/#layoutlmv3","title":"LayoutLMv3","text":"<p>Layout-aware retriever that understands document structure:</p> <pre><code>from Docs2Synth.retriever import train\n\n# Train LayoutLMv3 retriever\nmodel = train.train_retriever(\n    qa_pairs=\"qa_pairs.jsonl\",\n    model_name=\"microsoft/layoutlmv3-base\",\n    output_dir=\"models/layoutlmv3-retriever\"\n)\n</code></pre>"},{"location":"workflow/retriever-training/#bert-variants","title":"BERT Variants","text":"<p>Standard BERT-based models:</p> <ul> <li><code>bert-base-uncased</code></li> <li><code>roberta-base</code></li> <li><code>distilbert-base-uncased</code> (Faster, smaller)</li> </ul>"},{"location":"workflow/retriever-training/#basic-training","title":"Basic Training","text":""},{"location":"workflow/retriever-training/#cli-usage","title":"CLI Usage","text":"<pre><code># Train with default settings\ndocs2synth train-retriever qa_pairs.jsonl \\\n    --output-dir models/retriever\n\n# Custom model\ndocs2synth train-retriever qa_pairs.jsonl \\\n    --output-dir models/retriever \\\n    --model-name sentence-transformers/all-mpnet-base-v2 \\\n    --epochs 5 \\\n    --batch-size 32\n</code></pre>"},{"location":"workflow/retriever-training/#python-api","title":"Python API","text":"<pre><code>from Docs2Synth.retriever import train\n\n# Load QA pairs\nqa_pairs = train.load_qa_pairs(\"qa_pairs.jsonl\")\n\n# Train retriever\nmodel = train.train_retriever(\n    qa_pairs=qa_pairs,\n    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n    output_dir=\"models/retriever\",\n    epochs=5,\n    batch_size=32,\n    learning_rate=2e-5\n)\n\nprint(f\"Model saved to {model.output_dir}\")\n</code></pre>"},{"location":"workflow/retriever-training/#training-configuration","title":"Training Configuration","text":""},{"location":"workflow/retriever-training/#basic-configuration","title":"Basic Configuration","text":"<pre><code>training_config = {\n    \"model_name\": \"sentence-transformers/all-mpnet-base-v2\",\n    \"epochs\": 5,\n    \"batch_size\": 32,\n    \"learning_rate\": 2e-5,\n    \"warmup_steps\": 500,\n    \"evaluation_steps\": 1000,\n    \"save_steps\": 1000,\n}\n\nmodel = train.train_retriever(\n    qa_pairs=qa_pairs,\n    **training_config\n)\n</code></pre>"},{"location":"workflow/retriever-training/#advanced-configuration","title":"Advanced Configuration","text":"<pre><code>advanced_config = {\n    # Model settings\n    \"model_name\": \"microsoft/layoutlmv3-base\",\n    \"max_seq_length\": 512,\n    \"pooling_mode\": \"mean\",\n\n    # Training settings\n    \"epochs\": 10,\n    \"batch_size\": 16,\n    \"learning_rate\": 2e-5,\n    \"weight_decay\": 0.01,\n    \"warmup_ratio\": 0.1,\n\n    # Loss function\n    \"loss\": \"MultipleNegativesRankingLoss\",\n    \"scale\": 20.0,\n\n    # Evaluation\n    \"evaluation_steps\": 500,\n    \"eval_batch_size\": 64,\n\n    # Hardware\n    \"use_amp\": True,  # Automatic Mixed Precision\n    \"num_workers\": 4,\n    \"device\": \"cuda\",\n}\n\nmodel = train.train_retriever(\n    qa_pairs=qa_pairs,\n    **advanced_config\n)\n</code></pre>"},{"location":"workflow/retriever-training/#loss-functions","title":"Loss Functions","text":""},{"location":"workflow/retriever-training/#multiple-negatives-ranking-loss","title":"Multiple Negatives Ranking Loss","text":"<p>Best for most use cases:</p> <pre><code>from Docs2Synth.retriever.losses import MultipleNegativesRankingLoss\n\nloss = MultipleNegativesRankingLoss(\n    model=model,\n    scale=20.0,  # Temperature for softmax\n    similarity_fct=\"cosine\"\n)\n</code></pre>"},{"location":"workflow/retriever-training/#contrastive-loss","title":"Contrastive Loss","text":"<p>For harder negative mining:</p> <pre><code>from Docs2Synth.retriever.losses import ContrastiveLoss\n\nloss = ContrastiveLoss(\n    model=model,\n    margin=0.5,\n    distance_metric=\"euclidean\"\n)\n</code></pre>"},{"location":"workflow/retriever-training/#data-preparation","title":"Data Preparation","text":""},{"location":"workflow/retriever-training/#from-qa-pairs","title":"From QA Pairs","text":"<pre><code>from Docs2Synth.retriever.dataloaders import QADataLoader\n\n# Load and prepare data\ndataloader = QADataLoader(\n    qa_pairs=\"qa_pairs.jsonl\",\n    train_split=0.8,\n    val_split=0.1,\n    test_split=0.1\n)\n\ntrain_data = dataloader.get_train_data()\nval_data = dataloader.get_val_data()\ntest_data = dataloader.get_test_data()\n</code></pre>"},{"location":"workflow/retriever-training/#hard-negative-mining","title":"Hard Negative Mining","text":"<p>Improve retriever quality with hard negatives:</p> <pre><code>from Docs2Synth.retriever import hard_negatives\n\n# Mine hard negatives\nenhanced_data = hard_negatives.mine_hard_negatives(\n    qa_pairs=qa_pairs,\n    corpus=document_corpus,\n    num_negatives=5,\n    strategy=\"bm25\"  # or \"random\", \"semi-hard\"\n)\n</code></pre>"},{"location":"workflow/retriever-training/#evaluation","title":"Evaluation","text":""},{"location":"workflow/retriever-training/#during-training","title":"During Training","text":"<pre><code>from Docs2Synth.retriever.evaluation import Evaluator\n\nevaluator = Evaluator(\n    val_data=val_data,\n    metrics=[\"hit@1\", \"hit@5\", \"hit@10\", \"mrr\", \"ndcg@10\"]\n)\n\n# Evaluate during training\nmodel = train.train_retriever(\n    qa_pairs=qa_pairs,\n    evaluator=evaluator,\n    evaluation_steps=500\n)\n</code></pre>"},{"location":"workflow/retriever-training/#post-training-evaluation","title":"Post-Training Evaluation","text":"<pre><code>from Docs2Synth.retriever.evaluation import evaluate_retriever\n\n# Evaluate trained model\nresults = evaluate_retriever(\n    model=model,\n    test_data=test_data,\n    metrics=[\"hit@1\", \"hit@5\", \"hit@10\", \"mrr\"]\n)\n\nprint(results)\n# {\n#   \"hit@1\": 0.75,\n#   \"hit@5\": 0.92,\n#   \"hit@10\": 0.96,\n#   \"mrr\": 0.82\n# }\n</code></pre>"},{"location":"workflow/retriever-training/#inference","title":"Inference","text":""},{"location":"workflow/retriever-training/#retrieve-documents","title":"Retrieve Documents","text":"<pre><code>from Docs2Synth.retriever.inference import Retriever\n\n# Load trained model\nretriever = Retriever.from_pretrained(\"models/retriever\")\n\n# Index documents\nretriever.index_documents(document_corpus)\n\n# Retrieve for a query\nresults = retriever.retrieve(\n    query=\"What is the main purpose of the system?\",\n    top_k=5\n)\n\nfor rank, result in enumerate(results, 1):\n    print(f\"{rank}. {result['document_id']} (score: {result['score']:.3f})\")\n</code></pre>"},{"location":"workflow/retriever-training/#batch-retrieval","title":"Batch Retrieval","text":"<pre><code># Retrieve for multiple queries\nqueries = [\"Query 1\", \"Query 2\", \"Query 3\"]\n\nresults = retriever.batch_retrieve(\n    queries=queries,\n    top_k=10,\n    batch_size=32\n)\n</code></pre>"},{"location":"workflow/retriever-training/#optimization","title":"Optimization","text":""},{"location":"workflow/retriever-training/#speed-optimization","title":"Speed Optimization","text":"<pre><code># Use ONNX for faster inference\nfrom Docs2Synth.retriever.optimization import optimize_for_inference\n\noptimized_model = optimize_for_inference(\n    model_path=\"models/retriever\",\n    format=\"onnx\",\n    quantization=\"dynamic\"\n)\n\n# 2-3x faster inference\n</code></pre>"},{"location":"workflow/retriever-training/#index-optimization","title":"Index Optimization","text":"<pre><code># Use FAISS for large-scale retrieval\nfrom Docs2Synth.retriever.indexing import FAISSIndex\n\nindex = FAISSIndex(\n    model=retriever,\n    index_type=\"IVF\",  # Inverted file index\n    nlist=100  # Number of clusters\n)\n\nindex.add_documents(document_corpus)\nresults = index.search(query, top_k=10)\n</code></pre>"},{"location":"workflow/retriever-training/#best-practices","title":"Best Practices","text":"<ol> <li>Start small: Begin with a lightweight model (MiniLM) for prototyping</li> <li>Use hard negatives: Significantly improves retrieval quality</li> <li>Monitor validation metrics: Watch for overfitting</li> <li>Tune hyperparameters: Learning rate and batch size matter</li> <li>Evaluate on held-out test set: Don't overfit to validation set</li> <li>Consider domain adaptation: Fine-tune on your specific document type</li> </ol>"},{"location":"workflow/retriever-training/#benchmarking","title":"Benchmarking","text":"<p>Track retrieval performance:</p> <pre><code>from Docs2Synth.retriever import benchmark\n\n# Run comprehensive benchmark\nresults = benchmark.evaluate_retriever(\n    model=model,\n    test_queries=test_queries,\n    document_corpus=corpus,\n    metrics=[\"hit@k\", \"mrr\", \"ndcg\", \"latency\"]\n)\n\n# Generate report\nbenchmark.generate_report(results, output=\"benchmark_report.html\")\n</code></pre>"},{"location":"workflow/retriever-training/#next-steps","title":"Next Steps","text":"<p>After training your retriever, you can:</p> <ul> <li>Deploy for RAG applications</li> <li>Integrate into production pipelines</li> <li>Continue monitoring and improving performance</li> </ul>"},{"location":"workflow/retriever-training/#api-reference","title":"API Reference","text":"<p>For detailed API documentation, see the API Reference.</p>"}]}